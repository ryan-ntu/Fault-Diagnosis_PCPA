nohup: ignoring input
2025-11-10 22:09:25,263 | INFO | ==== main.py started ====
2025-11-10 22:09:25,263 | INFO | Args: {'model': 'gae', 'epochs': 500, 'batch': 64, 'lr': 0.0001, 'patience': 20, 'seed': 23, 'device': 'cuda:2', 'save_path': None, 'optuna': True, 'trials': 20, 'verbose': True, 'log_file': 'logs/gae_run.log', 'start_node': 6, 'length_V_H': 8}
[I 2025-11-10 22:09:47,209] A new study created in memory with name: no-name-a24fdc32-e5ed-477e-ae3e-1c9bf368c966
2025-11-10 22:09:47,209 | INFO | Optuna study created (direction=minimize). Starting optimize...
Epoch 1/500  train_loss=0.706482  val_f1=0.4990  best_val_f1=0.4990
Epoch 11/500  train_loss=0.699967  val_f1=0.4995  best_val_f1=0.5016
Epoch 21/500  train_loss=0.693625  val_f1=0.5001  best_val_f1=0.5016
Epoch 31/500  train_loss=0.694588  val_f1=0.5013  best_val_f1=0.5016
Epoch 41/500  train_loss=0.693552  val_f1=0.5011  best_val_f1=0.5016
Early stopping triggered
Test F1: 0.5024
[I 2025-11-10 22:36:19,586] Trial 0 finished with value: 0.49836274509803924 and parameters: {'lr': 0.01, 'batch_size': 128, 'cheb_K': 4, 'dropout': 0.3}. Best is trial 0 with value: 0.49836274509803924.
Epoch 1/500  train_loss=0.620812  val_f1=0.6599  best_val_f1=0.6599
Epoch 11/500  train_loss=0.507782  val_f1=0.7001  best_val_f1=0.7166
Epoch 21/500  train_loss=0.496635  val_f1=0.7173  best_val_f1=0.7180
Epoch 31/500  train_loss=0.495902  val_f1=0.6834  best_val_f1=0.7199
Epoch 41/500  train_loss=0.494130  val_f1=0.7039  best_val_f1=0.7199
Early stopping triggered
Test F1: 0.7203
[I 2025-11-10 22:54:52,439] Trial 1 finished with value: 0.2801078431372549 and parameters: {'lr': 0.001, 'batch_size': 128, 'cheb_K': 2, 'dropout': 0.4}. Best is trial 1 with value: 0.2801078431372549.
Epoch 1/500  train_loss=0.587594  val_f1=0.7082  best_val_f1=0.7082
Epoch 11/500  train_loss=0.448294  val_f1=0.7714  best_val_f1=0.7714
Epoch 21/500  train_loss=0.429329  val_f1=0.7713  best_val_f1=0.7730
Epoch 31/500  train_loss=0.419585  val_f1=0.7684  best_val_f1=0.7805
Epoch 41/500  train_loss=0.413337  val_f1=0.7736  best_val_f1=0.7817
Epoch 51/500  train_loss=0.408177  val_f1=0.7710  best_val_f1=0.7817
Early stopping triggered
Test F1: 0.7819
[I 2025-11-10 23:10:21,064] Trial 2 finished with value: 0.21832843137254898 and parameters: {'lr': 0.001, 'batch_size': 256, 'cheb_K': 2, 'dropout': 0.2}. Best is trial 2 with value: 0.21832843137254898.
Epoch 1/500  train_loss=0.679866  val_f1=0.5585  best_val_f1=0.5585
Epoch 11/500  train_loss=0.693204  val_f1=0.5010  best_val_f1=0.5656
Epoch 21/500  train_loss=0.693780  val_f1=0.5016  best_val_f1=0.5656
Early stopping triggered
Test F1: 0.5639
[I 2025-11-10 23:14:53,904] Trial 3 finished with value: 0.4344166666666667 and parameters: {'lr': 0.01, 'batch_size': 512, 'cheb_K': 2, 'dropout': 0.4}. Best is trial 2 with value: 0.21832843137254898.
Epoch 1/500  train_loss=0.549234  val_f1=0.7269  best_val_f1=0.7269
Epoch 11/500  train_loss=0.444417  val_f1=0.7652  best_val_f1=0.7673
Epoch 21/500  train_loss=0.448881  val_f1=0.7580  best_val_f1=0.7726
Epoch 31/500  train_loss=0.444355  val_f1=0.7639  best_val_f1=0.7726
Early stopping triggered
Test F1: 0.7725
[I 2025-11-10 23:57:14,483] Trial 4 finished with value: 0.22738235294117648 and parameters: {'lr': 0.001, 'batch_size': 64, 'cheb_K': 4, 'dropout': 0.2}. Best is trial 2 with value: 0.21832843137254898.
Epoch 1/500  train_loss=49.964425  val_f1=0.4999  best_val_f1=0.4999
Epoch 11/500  train_loss=49.981375  val_f1=0.4999  best_val_f1=0.4999
Epoch 21/500  train_loss=49.980742  val_f1=0.4999  best_val_f1=0.4999
Early stopping triggered
Test F1: 0.4986
[I 2025-11-11 00:11:15,362] Trial 5 finished with value: 0.5000882352941176 and parameters: {'lr': 0.01, 'batch_size': 128, 'cheb_K': 6, 'dropout': 0.2}. Best is trial 2 with value: 0.21832843137254898.
Epoch 1/500  train_loss=0.678190  val_f1=0.6015  best_val_f1=0.6015
Epoch 11/500  train_loss=0.489445  val_f1=0.7416  best_val_f1=0.7416
Epoch 21/500  train_loss=0.472276  val_f1=0.7471  best_val_f1=0.7482
Epoch 31/500  train_loss=0.464900  val_f1=0.7466  best_val_f1=0.7482
Epoch 41/500  train_loss=0.460879  val_f1=0.7461  best_val_f1=0.7509
Epoch 51/500  train_loss=0.457441  val_f1=0.7473  best_val_f1=0.7515
Epoch 61/500  train_loss=0.457032  val_f1=0.7496  best_val_f1=0.7537
Epoch 71/500  train_loss=0.454912  val_f1=0.7381  best_val_f1=0.7537
Early stopping triggered
Test F1: 0.7545
[I 2025-11-11 00:30:20,295] Trial 6 finished with value: 0.24634313725490198 and parameters: {'lr': 0.001, 'batch_size': 512, 'cheb_K': 4, 'dropout': 0.4}. Best is trial 2 with value: 0.21832843137254898.
Epoch 1/500  train_loss=0.766559  val_f1=0.4984  best_val_f1=0.4984
Epoch 11/500  train_loss=35.184397  val_f1=0.5004  best_val_f1=0.5004
Epoch 21/500  train_loss=35.110571  val_f1=0.5004  best_val_f1=0.5004
Early stopping triggered
Test F1: 0.5012
[I 2025-11-11 00:45:50,917] Trial 7 finished with value: 0.4996176470588235 and parameters: {'lr': 0.01, 'batch_size': 64, 'cheb_K': 2, 'dropout': 0.3}. Best is trial 2 with value: 0.21832843137254898.
Epoch 1/500  train_loss=0.928267  val_f1=0.5003  best_val_f1=0.5003
Epoch 11/500  train_loss=0.693154  val_f1=0.5016  best_val_f1=0.5016
Epoch 21/500  train_loss=0.693147  val_f1=0.5016  best_val_f1=0.5016
Early stopping triggered
Test F1: 0.5040
[I 2025-11-11 00:54:52,285] Trial 8 finished with value: 0.4983921568627451 and parameters: {'lr': 0.0001, 'batch_size': 256, 'cheb_K': 6, 'dropout': 0.2}. Best is trial 2 with value: 0.21832843137254898.
Epoch 1/500  train_loss=4.090435  val_f1=0.5016  best_val_f1=0.5016
Epoch 11/500  train_loss=0.693154  val_f1=0.5016  best_val_f1=0.5016
Epoch 21/500  train_loss=0.693158  val_f1=0.5016  best_val_f1=0.5016
Early stopping triggered
Test F1: 0.5040
[I 2025-11-11 01:09:15,800] Trial 9 finished with value: 0.4983921568627451 and parameters: {'lr': 0.0001, 'batch_size': 128, 'cheb_K': 6, 'dropout': 0.4}. Best is trial 2 with value: 0.21832843137254898.
Epoch 1/500  train_loss=0.591845  val_f1=0.6943  best_val_f1=0.6943
Epoch 11/500  train_loss=0.442349  val_f1=0.7645  best_val_f1=0.7699
Epoch 21/500  train_loss=0.423026  val_f1=0.7737  best_val_f1=0.7794
Epoch 31/500  train_loss=0.414704  val_f1=0.7777  best_val_f1=0.7794
Epoch 41/500  train_loss=0.408951  val_f1=0.7744  best_val_f1=0.7801
Epoch 51/500  train_loss=0.404866  val_f1=0.7773  best_val_f1=0.7801
Early stopping triggered
Test F1: 0.7791
[I 2025-11-11 01:23:58,157] Trial 10 finished with value: 0.21993137254901962 and parameters: {'lr': 0.001, 'batch_size': 256, 'cheb_K': 2, 'dropout': 0.2}. Best is trial 2 with value: 0.21832843137254898.
Epoch 1/500  train_loss=0.584386  val_f1=0.7060  best_val_f1=0.7060
Epoch 11/500  train_loss=0.440430  val_f1=0.7657  best_val_f1=0.7747
Epoch 21/500  train_loss=0.422826  val_f1=0.7716  best_val_f1=0.7812
Epoch 31/500  train_loss=0.414257  val_f1=0.7695  best_val_f1=0.7832
Epoch 41/500  train_loss=0.408760  val_f1=0.7729  best_val_f1=0.7832
Early stopping triggered
Test F1: 0.7836
[I 2025-11-11 01:36:13,173] Trial 11 finished with value: 0.21678921568627452 and parameters: {'lr': 0.001, 'batch_size': 256, 'cheb_K': 2, 'dropout': 0.2}. Best is trial 11 with value: 0.21678921568627452.
Epoch 1/500  train_loss=0.595161  val_f1=0.6928  best_val_f1=0.6928
Epoch 11/500  train_loss=0.440949  val_f1=0.7710  best_val_f1=0.7737
Epoch 21/500  train_loss=0.423411  val_f1=0.7712  best_val_f1=0.7830
Epoch 31/500  train_loss=0.415297  val_f1=0.7811  best_val_f1=0.7830
Epoch 41/500  train_loss=0.409115  val_f1=0.7798  best_val_f1=0.7830
Epoch 51/500  train_loss=0.404851  val_f1=0.7815  best_val_f1=0.7830
Early stopping triggered
Test F1: 0.7830
[I 2025-11-11 01:52:03,996] Trial 12 finished with value: 0.2169852941176471 and parameters: {'lr': 0.001, 'batch_size': 256, 'cheb_K': 2, 'dropout': 0.2}. Best is trial 11 with value: 0.21678921568627452.
Epoch 1/500  train_loss=0.596215  val_f1=0.6933  best_val_f1=0.6933
Epoch 11/500  train_loss=0.457194  val_f1=0.7543  best_val_f1=0.7544
Epoch 21/500  train_loss=0.436162  val_f1=0.7680  best_val_f1=0.7680
Epoch 31/500  train_loss=0.423276  val_f1=0.7624  best_val_f1=0.7719
Epoch 41/500  train_loss=0.417072  val_f1=0.7745  best_val_f1=0.7765
Epoch 51/500  train_loss=0.411679  val_f1=0.7711  best_val_f1=0.7788
Epoch 61/500  train_loss=0.407796  val_f1=0.7691  best_val_f1=0.7788
Epoch 71/500  train_loss=0.404463  val_f1=0.7828  best_val_f1=0.7828
Epoch 81/500  train_loss=0.402718  val_f1=0.7769  best_val_f1=0.7828
Epoch 91/500  train_loss=0.400689  val_f1=0.7746  best_val_f1=0.7828
Early stopping triggered
Test F1: 0.7823
[I 2025-11-11 02:18:10,876] Trial 13 finished with value: 0.21721078431372554 and parameters: {'lr': 0.001, 'batch_size': 256, 'cheb_K': 2, 'dropout': 0.2}. Best is trial 11 with value: 0.21678921568627452.
Epoch 1/500  train_loss=0.588344  val_f1=0.6929  best_val_f1=0.6929
Epoch 11/500  train_loss=0.454645  val_f1=0.7554  best_val_f1=0.7554
Epoch 21/500  train_loss=0.430518  val_f1=0.7726  best_val_f1=0.7726
Epoch 31/500  train_loss=0.417767  val_f1=0.7713  best_val_f1=0.7789
Epoch 41/500  train_loss=0.411249  val_f1=0.7732  best_val_f1=0.7792
Epoch 51/500  train_loss=0.406040  val_f1=0.7810  best_val_f1=0.7810
Epoch 61/500  train_loss=0.403046  val_f1=0.7670  best_val_f1=0.7810
Epoch 71/500  train_loss=0.399977  val_f1=0.7718  best_val_f1=0.7810
Early stopping triggered
Test F1: 0.7803
[I 2025-11-11 02:38:21,369] Trial 14 finished with value: 0.21899999999999997 and parameters: {'lr': 0.001, 'batch_size': 256, 'cheb_K': 2, 'dropout': 0.2}. Best is trial 11 with value: 0.21678921568627452.
Epoch 1/500  train_loss=0.586780  val_f1=0.6913  best_val_f1=0.6913
Epoch 11/500  train_loss=0.435732  val_f1=0.7573  best_val_f1=0.7639
Epoch 21/500  train_loss=0.420287  val_f1=0.7686  best_val_f1=0.7725
Epoch 31/500  train_loss=0.411780  val_f1=0.7714  best_val_f1=0.7725
Early stopping triggered
Test F1: 0.7728
[I 2025-11-11 02:47:45,336] Trial 15 finished with value: 0.22754901960784313 and parameters: {'lr': 0.001, 'batch_size': 256, 'cheb_K': 2, 'dropout': 0.2}. Best is trial 11 with value: 0.21678921568627452.
Epoch 1/500  train_loss=0.671678  val_f1=0.5857  best_val_f1=0.5857
Epoch 11/500  train_loss=0.520885  val_f1=0.7196  best_val_f1=0.7196
Epoch 21/500  train_loss=0.483743  val_f1=0.7343  best_val_f1=0.7369
Epoch 31/500  train_loss=0.465903  val_f1=0.7478  best_val_f1=0.7478
Epoch 41/500  train_loss=0.453351  val_f1=0.7584  best_val_f1=0.7584
Epoch 51/500  train_loss=0.444344  val_f1=0.7587  best_val_f1=0.7627
Epoch 61/500  train_loss=0.439260  val_f1=0.7644  best_val_f1=0.7644
Epoch 71/500  train_loss=0.434503  val_f1=0.7659  best_val_f1=0.7659
Epoch 81/500  train_loss=0.430044  val_f1=0.7651  best_val_f1=0.7668
Epoch 91/500  train_loss=0.426725  val_f1=0.7660  best_val_f1=0.7673
Epoch 101/500  train_loss=0.424578  val_f1=0.7636  best_val_f1=0.7674
Epoch 111/500  train_loss=0.422288  val_f1=0.7643  best_val_f1=0.7674
Epoch 121/500  train_loss=0.420746  val_f1=0.7630  best_val_f1=0.7677
Epoch 131/500  train_loss=0.418606  val_f1=0.7655  best_val_f1=0.7680
Epoch 141/500  train_loss=0.416798  val_f1=0.7677  best_val_f1=0.7680
Early stopping triggered
Test F1: 0.7676
[I 2025-11-11 03:29:03,365] Trial 16 finished with value: 0.231985294117647 and parameters: {'lr': 0.0001, 'batch_size': 256, 'cheb_K': 2, 'dropout': 0.3}. Best is trial 11 with value: 0.21678921568627452.
Epoch 1/500  train_loss=0.587235  val_f1=0.7048  best_val_f1=0.7048
Epoch 11/500  train_loss=0.444721  val_f1=0.7688  best_val_f1=0.7688
Epoch 21/500  train_loss=0.422810  val_f1=0.7766  best_val_f1=0.7769
Epoch 31/500  train_loss=0.414128  val_f1=0.7696  best_val_f1=0.7769
Epoch 41/500  train_loss=0.407785  val_f1=0.7794  best_val_f1=0.7794
Epoch 51/500  train_loss=0.402879  val_f1=0.7762  best_val_f1=0.7794
Epoch 61/500  train_loss=0.399392  val_f1=0.7709  best_val_f1=0.7794
Early stopping triggered
Test F1: 0.7809
[I 2025-11-11 03:46:34,872] Trial 17 finished with value: 0.22056862745098038 and parameters: {'lr': 0.001, 'batch_size': 256, 'cheb_K': 2, 'dropout': 0.2}. Best is trial 11 with value: 0.21678921568627452.
Epoch 1/500  train_loss=0.552107  val_f1=0.6962  best_val_f1=0.6962
Epoch 11/500  train_loss=0.446227  val_f1=0.7678  best_val_f1=0.7678
Epoch 21/500  train_loss=0.441516  val_f1=0.7681  best_val_f1=0.7685
Epoch 31/500  train_loss=0.443678  val_f1=0.7654  best_val_f1=0.7685
Epoch 41/500  train_loss=0.439567  val_f1=0.7707  best_val_f1=0.7707
Epoch 51/500  train_loss=0.443478  val_f1=0.7630  best_val_f1=0.7707
Epoch 61/500  train_loss=0.442925  val_f1=0.7598  best_val_f1=0.7707
Early stopping triggered
Test F1: 0.7711
[I 2025-11-11 04:51:00,322] Trial 18 finished with value: 0.22933823529411768 and parameters: {'lr': 0.001, 'batch_size': 64, 'cheb_K': 4, 'dropout': 0.2}. Best is trial 11 with value: 0.21678921568627452.
Epoch 1/500  train_loss=1.873883  val_f1=0.5002  best_val_f1=0.5002
Epoch 11/500  train_loss=0.693164  val_f1=0.5016  best_val_f1=0.5016
Epoch 21/500  train_loss=0.693152  val_f1=0.5016  best_val_f1=0.5016
Early stopping triggered
Test F1: 0.5040
[I 2025-11-11 04:57:49,429] Trial 19 finished with value: 0.4983921568627451 and parameters: {'lr': 0.0001, 'batch_size': 512, 'cheb_K': 6, 'dropout': 0.3}. Best is trial 11 with value: 0.21678921568627452.
2025-11-11 04:57:49,429 | INFO | Best trial: 11
2025-11-11 04:57:49,430 | INFO | Best value: 0.21678921568627452
2025-11-11 04:57:49,430 | INFO | Best params: {'lr': 0.001, 'batch_size': 256, 'cheb_K': 2, 'dropout': 0.2}
Epoch 1/500  train_loss=0.694685  val_f1=0.4990  best_val_f1=0.4990
Epoch 11/500  train_loss=0.693163  val_f1=0.5001  best_val_f1=0.5016
Epoch 21/500  train_loss=0.693158  val_f1=0.4997  best_val_f1=0.5016
Epoch 31/500  train_loss=0.693515  val_f1=0.5007  best_val_f1=0.5018
Epoch 41/500  train_loss=0.693161  val_f1=0.5016  best_val_f1=0.5018
Early stopping triggered
Test F1: 0.5027
2025-11-11 05:51:09,462 | INFO | Saved best model to model/case30_cnn_transformer.pth
2025-11-11 05:51:09,462 | INFO | Logs written to logs/gae_run.log
